{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Email&phoneScraperUsingBeautifulSoup.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQ8FW03O314"
      },
      "source": [
        "import re\r\n",
        "import requests\r\n",
        "from urllib.parse import urlsplit\r\n",
        "from collections import deque\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import pandas as pd\r\n",
        "from google.colab import files\r\n",
        "import xlrd\r\n",
        "import json\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "links = pd.read_excel(\"Any Excel file\", usecols= range(0,3)) \r\n",
        "company = links[\"Corresponding column name of link \"]\r\n",
        "links = links[\"column name with urls\"]\r\n",
        "FILE_NAME = 'output.json' # Name of output file\r\n",
        "\r\n",
        "with open(FILE_NAME,\"w\") as file:\r\n",
        "  json.dump([],file)\r\n",
        "\r\n",
        "\r\n",
        "duplicate = deque()\r\n",
        "com = deque()\r\n",
        "for i in range(len(links)):\r\n",
        "  link = links[i]\r\n",
        "  duplicate.append(link)\r\n",
        "#duplicate\r\n",
        "\r\n",
        "\r\n",
        "def save(x):\r\n",
        "    with open(FILE_NAME,'w') as f:\r\n",
        "        json.dump(x,f)\r\n",
        "\r\n",
        "scraped = set()\r\n",
        "emails = set()\r\n",
        "phoneno = set()\r\n",
        "final_emails = []\r\n",
        "final_set = []\r\n",
        "k = 0\r\n",
        "for t in range(len(duplicate)):\r\n",
        "  original_url = duplicate[t]\r\n",
        "  unscraped = deque([original_url])\r\n",
        "  emails.clear()\r\n",
        "  count = 0\r\n",
        "  while len(unscraped) and count < 10:\r\n",
        "       \r\n",
        "\r\n",
        "        url = unscraped.popleft()  \r\n",
        "        scraped.add(url)\r\n",
        "        try:\r\n",
        "          parts = urlsplit(url)\r\n",
        "        except:\r\n",
        "          continue  \r\n",
        "        base_url = \"{0.scheme}://{0.netloc}\".format(parts)\r\n",
        "        if '/' in parts.path:\r\n",
        "          path = url[:url.rfind('/')+1]\r\n",
        "        else:\r\n",
        "          path = url\r\n",
        "\r\n",
        "        print(\"Crawling URL %s\" % url)\r\n",
        "        try:\r\n",
        "            response = requests.get(url)\r\n",
        "        except:\r\n",
        "            continue\r\n",
        "\r\n",
        "        soup = BeautifulSoup(response.text, 'lxml')\r\n",
        "        \r\n",
        "        for anchor in soup.find_all(\"a\"):\r\n",
        "          if anchor.text != \"Contact Us\" and anchor.text != \"Contact\"and anchor.text != \"About Us\" and anchor.text != \"About\" :\r\n",
        "            continue\r\n",
        "          \r\n",
        "          if \"href\" in anchor.attrs:\r\n",
        "            link = anchor.attrs[\"href\"]\r\n",
        "          else:\r\n",
        "            link = ''\r\n",
        "          \r\n",
        "          \r\n",
        "          if link.startswith('/'):\r\n",
        "                link = base_url + link\r\n",
        "            \r\n",
        "            \r\n",
        "          elif not link.startswith('http'):\r\n",
        "                \r\n",
        "                link = path + link\r\n",
        "\r\n",
        "          len1 = len(link)\r\n",
        "          if(link[len1-1] == '#' ):\r\n",
        "            break     \r\n",
        "\r\n",
        "\r\n",
        "          if not link.endswith(\".gz\"):\r\n",
        "            if not link in unscraped and not link in scraped:\r\n",
        "                unscraped.append(link)\r\n",
        "          \r\n",
        "        # For Phone Number\r\n",
        "        new_phonea = re.findall(r'\\(?\\b[2-9][0-9]{2}\\)?[-][2-9][0-9]{2}[-][0-9]{4}\\b', response.text)\r\n",
        "        phoneno.update(new_phonea)\r\n",
        "        \r\n",
        "        # For Emails\r\n",
        "        new_emails_com = set(re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.com\", response.text, re.I))\r\n",
        "        new_emails_org = set(re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.org\", response.text, re.I))\r\n",
        "        new_emails_au = set(re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.au\", response.text, re.I))\r\n",
        "        new_emails_in = set(re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.in\", response.text, re.I))\r\n",
        "        new_emails_af = set(re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.af\", response.text, re.I))\r\n",
        "        new_emails_ar = set(re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.ar\", response.text, re.I))\r\n",
        "        new_emails_us = set(re.findall(r\"[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.us\", response.text, re.I))\r\n",
        "        emails.update(new_emails_org)\r\n",
        "        emails.update(new_emails_com)\r\n",
        "        emails.update(new_emails_au)\r\n",
        "        emails.update(new_emails_af)\r\n",
        "        emails.update(new_emails_ar)\r\n",
        "        emails.update(new_emails_in)\r\n",
        "        emails.update(new_emails_us)\r\n",
        "        count += 1\r\n",
        "  # List to store multiple emails\r\n",
        "  e = []\r\n",
        "  for x in emails:\r\n",
        "    print(x)\r\n",
        "    e.append(x)\r\n",
        "  # List to store multiple phone numbers\r\n",
        "  b = []\r\n",
        "  for x in phoneno:\r\n",
        "    print(x)\r\n",
        "    b.append(x)\r\n",
        " \r\n",
        " ## Storing the details in JSON file defined above\r\n",
        "  final_emails.append(e)\r\n",
        "  with open(FILE_NAME) as file:\r\n",
        "    data = json.load(file)\r\n",
        "    organisation = {\"Name\" : company[k],\"email\" : e,\"phoneNo\" : b} # Code to store the json objects for easier conversion to csv file later\r\n",
        "    print(organisation)\r\n",
        "    data.append(organisation)\r\n",
        "    save(data)\r\n",
        "  k += 1   \r\n",
        "print(final_emails)\r\n",
        "    \r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN0_6M9xf3Ts"
      },
      "source": [
        "### Print the json file\r\n",
        "\r\n",
        "\r\n",
        "with open('output.json', 'r') as raw_output:\r\n",
        "    data = raw_output.read()\r\n",
        "    output = json.loads(data)\r\n",
        "print(output)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}